{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Foody practice",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaV4cPo1GgJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YStz4h57GgkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "from tqdm import tqdm #https://tqdm.github.io/\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5IB55OMJhkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "mpl.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOx9oRpGoor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_pickle(\"/content/drive/My Drive/foody_data.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC1Jmez1Om0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XEM 5 DONG DAU TIEN\n",
        "# XEM 5 DONG CUOI CUNG\n",
        "# XEM 5 DONG NGAU NHIEN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPLjH8kCcNty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LẤY MẪU NGẪU NHIÊN 10K MẪU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUhyMMaN3mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XEM HÌNH DẠNG CỦA TẬP DỮ LIỆU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwLjKFeryKbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt_3NZ3QGq--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XEM THÔNG TIN, KIỂU DỮ LIỆU CỦA TẬP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgxxQlyASjKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MÔ TẢ DỮ LIỆU BẰNG COUNT, 25%, 50%,.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-a4mhZ8HlrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VẼ HISTOGRAM 20 BIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnyh4G4ONRk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XEM CÁC GIÁ TRỊ UNIQUE CỦA CỘT AVG_SCORE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRjrXDdSNVoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ĐẾM SỐ LẦN XUẤT HIỆN CỦA TỪNG GIÁ TRỊ TRONG CỘT AVG_SCORE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StJ5HUGAHmVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VẼ BOXPLOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXB35LFOLXKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ĐẾM SỐ GIÁ TRỊ NULL CỦA TỪNG CỘT (FEATURE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcXPKx_eLbJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XỬ LÝ NULL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v0i-EmjicV_I",
        "colab": {}
      },
      "source": [
        "# TRUY XUẤT 1 DÒNG BẤT KÌ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UmuHtN3gHNn",
        "colab_type": "text"
      },
      "source": [
        "## INPUT PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6PKJQZSgmsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_list = []\n",
        "for element in data['review_content']:\n",
        "    tmp = re.sub(r'\\d+', '', element) #remove num\n",
        "    tmp = re.sub(r'\\n+', ' ', tmp) #remove redundant endlines\n",
        "    tmp = re.sub(r'\\r+', ' ', tmp) #remove redundant spaces\n",
        "    tmp = re.sub(r'\\t+', ' ', tmp) #remove redundant spaces\n",
        "    tmp_list.append(tmp.strip())\n",
        "data['review_content'] = tmp_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6x9bcGDTDmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def simplify_avg_score(df):\n",
        "    bins = (0, 7.6, 10)\n",
        "    group_names = ['group 1','group 2']\n",
        "    categories = pd.cut(df.avg_score, bins, labels=group_names)\n",
        "    df.avg_score = categories\n",
        "    \n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(df.avg_score)\n",
        "    df.avg_score = le.transform(df.avg_score)\n",
        "    return df\n",
        "\n",
        "# GỘP CỘT AVG_SCORE THÀNH CÁC LỚP (CLASS) THEO BIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeE7ynxVBpQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY5_0DTm52FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['avg_score'] = data['avg_score'].astype(int) #float str\n",
        "data = simplify_avg_score(data)\n",
        "data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYvJqpYkyMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GÁN INPUT X BẰNG REVIEW_CONTENT, Y BẰNG AVG_SCORE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK-FODhC9R1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs9GG4phlCOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CHIA X, Y THÀNH TẬP TRAIN, TEST THEO TỶ LỆ ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKJsyiZmD6W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7_-58-bh7Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  ÁP DỤNG TFIDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_df=0.5, max_features=10000)\n",
        "\n",
        "...................."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aYxjs05OFZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_processed[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11IiqwqgLaRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FIT BẰNG LOGISTIC REGRESSION CỦA SKLEARN\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vHjbDR_O4RU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_prediction = model.predict(X_test_processed) #=> y_pred\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, model_prediction))\n",
        "print(\"F1: \", f1_score(y_test, model_prediction , average=\"weighted\"))\n",
        "\n",
        "# #https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/\n",
        "# #https://stackoverflow.com/questions/53394984/micro-f1-score-in-scikit-learn-with-class-imbalance\n",
        "# #https://datascience.stackexchange.com/questions/40900/whats-the-difference-between-sklearn-f1-score-micro-and-weighted-for-a-mult\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t-pBPqmeIt_",
        "colab_type": "text"
      },
      "source": [
        "## ========================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n99Fd06lWXvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x  #gpu\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OChpswycmFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD STRATEGY CHẠY NHIỀU GPU TRÊN 1 MÁY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khit7xoLxhod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIẾT KẾ MÔ HÌNH MLP BẰNG FUNCTION model(), SỬ DỤNG TF.KERAS, DROPOUT, HÀM ACTIVATION\n",
        "\n",
        "\n",
        "def make_model():\n",
        "    \n",
        "    return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD_SeKvT8lao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD MÔ HÌNH VÀO STRATEGY\n",
        ".............\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y2vQtLt5PGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIẾT LẬP EARLY STOPPING, FIT MÔ HÌNH, CHO HIỂN THỊ LOG\n",
        "early_stopping = \n",
        "\n",
        "history = model.fit(\n",
        "    X_train_processed.toarray(), y_train,\n",
        "    epochs=...,\n",
        "    verbose=...,\n",
        "    validation_data = (X_test_processed.toarray(), y_test),\n",
        "    callbacks=[],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH8Fnr1-P4BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(......)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncQ4VTXJJnHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print (confusion_matrix(y_test, y_pred2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh36jGNJIGwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred2 = []\n",
        "for y in y_pred:\n",
        "    y_pred2.append(np.argmax(y))\n",
        "\n",
        "print(accuracy_score(y_test, y_pred2))\n",
        "print(f1_score(y_test, y_pred2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oCHfqww7yGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VẼ ĐỒ THỊ CHO TRAINING/VALIDATION CỦA ACCURACY VÀ LOSS\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(4)\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY9JePJJM6yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSZ5opheghIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('/content/drive/My Drive/cc.vi.300.vec', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJ0sd01RMxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = []\n",
        "for x in X_train:\n",
        "    length.append(len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgkioj2iQ92v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics\n",
        "\n",
        "max_seq_len = np.round(statistics.mean(length)).astype(int)\n",
        "max_seq_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy0b23gjOWrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "\n",
        "MAX_NB_WORDS=10000\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "print(\"pre-processing train data...\")\n",
        "processed_docs_train = []\n",
        "for doc in tqdm(X_train):\n",
        "    tokens = tokenizer.tokenize(doc)\n",
        "    filtered = [word for word in tokens]\n",
        "    processed_docs_train.append(\" \".join(filtered))\n",
        "#end for\n",
        "\n",
        "processed_docs_test = []\n",
        "for doc in tqdm(X_test):\n",
        "    tokens = tokenizer.tokenize(doc)\n",
        "    filtered = [word for word in tokens]\n",
        "    processed_docs_test.append(\" \".join(filtered))\n",
        "#end for\n",
        "\n",
        "print(\"tokenizing input data...\")\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(processed_docs_train)\n",
        "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
        "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
        "word_index = tokenizer.word_index\n",
        "print(\"dictionary size: \", len(word_index))\n",
        "\n",
        "# #pad sequences\n",
        "word_seq_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
        "word_seq_test = sequence.pad_sequences(word_seq_test, maxlen=max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT7EBZgQEUAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(word_seq_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjQNm7EwWXHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(word_seq_test[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NEqas_LMoCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3qRQ5E0Pnmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 300\n",
        "\n",
        "#embedding matrix\n",
        "print('preparing embedding matrix...')\n",
        "words_not_found = []\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu6BRg02SRff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"sample words not found: \", np.random.choice(words_not_found, 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hUHXFxiBXE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(word_seq_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxRvakv_SZv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Flatten, LSTM, Bidirectional\n",
        "\n",
        "def make_model_classification2():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(nb_words, embed_dim,\n",
        "          weights=[embedding_matrix], input_length=max_seq_len))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True))) \n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Bidirectional(LSTM(32))) \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(..................)\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    \n",
        "    model.add(....................)\n",
        "\n",
        "    model.compile(\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpenfXLcSwNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    model = make_model_classification2()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKPjVcWS0lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "  word_seq_train, y_train, batch_size=...,\n",
        "  epochs=..., verbose=..., validation_data=(word_seq_test, y_test),\n",
        "  callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp-GfEIaS90H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DỰ ĐOÁN, IN KẾT QUẢ\n",
        "\n",
        "y_pred = model.predict(word_seq_test)\n",
        "\n",
        "y_pred2 = []\n",
        "for y in y_pred:\n",
        "    y_pred2.append(np.argmax(y))\n",
        "# y_pred2\n",
        "\n",
        "#in acc, f1, confusion matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmVOIOuMr77Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}