{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09 Introduction to TensorFlow-2.0.ipynb","provenance":[{"file_id":"1a_6JZXzspsOX-7mp53bxPRitBvmdiMhA","timestamp":1574241918629}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uRnOSIDdCeJA","colab_type":"text"},"source":["Copyright &copy; 2019 COTAI. All rights reserved."]},{"cell_type":"markdown","metadata":{"id":"HrY0aLbD0EfJ","colab_type":"text"},"source":["# Introduction to TensorFlow\n","**Why TensorFlow?**: \n","* Advantages of TensorFlow:\n","    * TensorFlow are supported widely by different programming languages (e.g. C/C++, Java, Python, etc.)\n","    * TensorFlow are supported widely by different types of devices (e.g. mobile, server, PC, etc.)\n","    * TensorFlow supports TPU while most of deep learning frameworks only support CPU and GPU\n","* Weakness of TensorFlow:\n","    * Hard to use due to computation graphs\n","    * TensorFlow are ill-organized\n","* Conclusion: TensorFlow is not very good for experimentation but good for commercialization\n","\n","**TensorFlow 1.0 and computation graph**:\n","* Computation graph: a graph whose:\n","    * Nodes: represent operations, variables, or placeholders (i.e. the place where we feed model inputs to the graph)\n","    * Edges: represent data, or multi-dimensional arrays (i.e. Tensors) which flow through the different operations\n","\n","<image src=\"https://miro.medium.com/max/2994/1*vPb9E0Yd1QUAD0oFmAgaOw.png\" width=\"750px\">\n","\n","* TensorFlow-1.0's idea:\n","    * Step 1: to construct a computational graph first and compile the graph\n","    * Step 2: for each execution, an input is fed into the graph\n","    * Step 3: the calculations are carried out throughout the graph\n","    * Step 4: the execution returns an output, which is produced by the computational graph\n","\n","**TensorFlow 2.0 and Eager execution mode**:\n","* Improvements from TensorFlow 1.0:\n","    * Easy-to-use since it doesn't rely on computation graph\n","    * Operate in the same manner as PyTorch, which is very research-friendly\n","* Conclusion: TensorFlow 2.0 are moving towards being good at both research and engineering\n","\n","**More about TensorFlow 1.0 and TensorFlow 2.0**:\n","* The idea of TensorFlow-2.0's eager execution: operations return concrete values instead of constructing a computational graph to run later\n","* Conclusion: TF 2.0 with Eager execution mode is easy to get started and debug models\n","    * Explain:\n","        * Originally, TF asks user to create a computational graph first, then it compiles the graph and allows user to run that graph\n","        * When the user runs a graph by feeding an input to it, every computation is carried out internally within the graph without any Python-friendly output for debugging\n","            * Example: you cannot print any intermediate output of the computation graph when running it\n","\n",">**NOTE**: note that in this class, we only practice with TensorFlow-2.0"]},{"cell_type":"markdown","metadata":{"id":"WqIJXNVl33N-","colab_type":"text"},"source":["# Practice with TensorFlow-2.0\n","## Basic steps\n","**Setup TensorFlow-2.0**:\n","* Step 0: switch to GPU runtime (for ones using Google Colab)\n","* Step 1: install TensorFlow-2.0 with GPU support"]},{"cell_type":"code","metadata":{"id":"S1_K_c4XFk7H","colab_type":"code","outputId":"3f12430f-0700-4ef2-9c23-4e3f5b9587e7","executionInfo":{"status":"ok","timestamp":1578757167708,"user_tz":-420,"elapsed":105562,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# uninstall existing TensorFlow (TF-1.5) of Google Colab\n","!pip uninstall -y tensorflow\n","# install TensorFlow-2.0 with GPU support\n","!pip install tensorflow-gpu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-1.15.0:\n","  Successfully uninstalled tensorflow-1.15.0\n","Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.5)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 40.8MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 41.8MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (42.0.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n","\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","Successfully installed google-auth-1.10.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"E9Pamxol4TuQ","colab_type":"text"},"source":["* Step 2: import TensorFlow and enable eager execution mode"]},{"cell_type":"code","metadata":{"id":"IXQNrUnR4bch","colab_type":"code","outputId":"dc8f6221-b901-4d0e-c52c-6d49bc9819a4","executionInfo":{"status":"ok","timestamp":1578757175332,"user_tz":-420,"elapsed":113160,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import tensorflow as tf\n","\n","print(tf.__version__)\n","tf.executing_eagerly()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2.1.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"uOCSFJxY43fc","colab_type":"text"},"source":["**Introduction to `tf.Tensor`**:\n","* `tf.Tensor`: the fundamental computation unit of TF-2.0, which stores concrete values (e.g. vector, matrix, tensor, et.c) just like NumPy arrays\n","* Switching between NumPy arrays and `tf.Tensor`s:\n","    * From `tf.Tensor` to NumPy array: `tf.Tensor.numpy()`"]},{"cell_type":"code","metadata":{"id":"SDDUYNKL6f_K","colab_type":"code","outputId":"632172ba-ad07-461a-d345-30c8531e9291","executionInfo":{"status":"ok","timestamp":1578757175333,"user_tz":-420,"elapsed":113153,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# declare some tensor\n","some_tensor = tf.constant([100, 20, 1.3])\n","print(type(some_tensor))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9VJVqA7H6-1n","colab_type":"code","outputId":"b7c3152c-f2b1-4250-d78a-197b12a63af9","executionInfo":{"status":"ok","timestamp":1578757175334,"user_tz":-420,"elapsed":113146,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# convert to NumPy array\n","some_numpy_array = some_tensor.numpy()\n","print(type(some_numpy_array))\n","print(some_numpy_array)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n","[100.   20.    1.3]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g0CTkwQF6_1E","colab_type":"code","outputId":"a5e18d9e-64f9-4766-de49-df64d81187ff","executionInfo":{"status":"ok","timestamp":1578757175335,"user_tz":-420,"elapsed":113140,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# convert back to tf.Tensor\n","some_tensor = tf.convert_to_tensor(some_numpy_array)\n","print(type(some_tensor))\n","print(some_tensor)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n","tf.Tensor([100.   20.    1.3], shape=(3,), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cvhq5AkAvKDP","colab_type":"code","outputId":"9e172c94-d721-421f-de49-45a604f39479","executionInfo":{"status":"ok","timestamp":1578757176216,"user_tz":-420,"elapsed":114011,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np\n","\n","a = np.array([2, 7, 9, 5])\n","\n","# print(a*3)\n","\n","b = tf.convert_to_tensor(a)\n","\n","print(b)\n","print(b*3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tf.Tensor([2 7 9 5], shape=(4,), dtype=int64)\n","tf.Tensor([ 6 21 27 15], shape=(4,), dtype=int64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8emQLzRNgHpf"},"source":["* Noticeable points:\n","    * NumPy operations accept `tf.Tensor` arguments\n","    * TF math operations convert Python objects and NumPy arrays to `tf.Tensor` objects\n","* Overall code example:"]},{"cell_type":"code","metadata":{"id":"nxjlT5tZ6uz-","colab_type":"code","outputId":"718fb2e1-9bfe-4d0c-cf8a-58908397fc5a","executionInfo":{"status":"ok","timestamp":1578757176217,"user_tz":-420,"elapsed":113987,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":274}},"source":["def fizzbuzz(max_num):\n","    \"\"\"This function prints \"Fizz\" and \"Buzz\" depending on whether `num` is divisible by 3 or 5\n","    \"\"\"\n","    counter = tf.constant(0)\n","    max_num = tf.convert_to_tensor(max_num)\n","    for num in range(1, max_num+1):\n","        num = tf.constant(num)\n","        if int(num % 3) == 0 and int(num % 5) == 0:\n","            print('FizzBuzz')\n","        elif int(num % 3) == 0:\n","            print('Fizz')\n","        elif int(num % 5) == 0:\n","            print('Buzz')\n","        else:\n","            print(num.numpy())\n","        counter += 1\n","\n","fizzbuzz(15)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n","2\n","Fizz\n","4\n","Buzz\n","Fizz\n","7\n","8\n","Fizz\n","Buzz\n","11\n","Fizz\n","13\n","14\n","FizzBuzz\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d5WQUNb07ekO","colab_type":"text"},"source":["## Deep learning with TensorFlow eager execution\n","**Computing gradients with TF**: gradient computation is automated with TensorFlow\n","* `tf.GradientTape`: used to trace operations for computing gradients later\n","    * Step 1: all forward-pass operations get recorded to a tape\n","    * Step 2: to compute the gradient, play the tape backwards and then discard\n","* Code:"]},{"cell_type":"code","metadata":{"id":"ymzznXVw7v5G","colab_type":"code","outputId":"d4c9c091-99b4-43d8-d0e7-fb9a428f6895","executionInfo":{"status":"ok","timestamp":1578757176218,"user_tz":-420,"elapsed":113980,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["w = tf.Variable([[2.0]])\n","with tf.GradientTape() as tape:\n","  loss = w*w*w + w*w + 3\n","\n","grad = tape.gradient(loss, w) # compute gradient of `loss` w.r.t `w`\n","print(grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tf.Tensor([[16.]], shape=(1, 1), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gwgr4acsKGRd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6k4BteuX704w","colab_type":"text"},"source":["**Variables and Optimizers**:\n","* `tf.Variable`: objects store mutable `tf.Tensor`-like values, which allow computing gradient computation\n","    * Example:"]},{"cell_type":"code","metadata":{"id":"WbSUBLfV996G","colab_type":"code","outputId":"2016635b-988c-4f3b-c8da-7b98bf286f67","executionInfo":{"status":"error","timestamp":1578757176678,"user_tz":-420,"elapsed":114435,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":234}},"source":["A @ B \n","tf.matmul()\n","\n","tf.math.log()\n","tf.nn.relu()\n","tf.nn.softmax()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-4ca35875727b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"]}]},{"cell_type":"code","metadata":{"id":"9WOEUh0y7w8W","colab_type":"code","colab":{}},"source":["# define some simple linear model with weights `W` and biases `B`\n","class Linear(tf.keras.Model):\n","    def __init__(self):\n","        super(Linear, self).__init__()\n","        self.W = tf.Variable(5., name='weight')\n","        self.B = tf.Variable(10., name='bias')\n","        \n","    def call(self, inputs):\n","        X = inputs\n","        y_hat = X * self.W + self.B\n","        return y_hat\n","\n","# define some loss function (the loss below is called \"mean-squared error\" (MSE))\n","def loss(model, inputs, targets):\n","    y     = targets\n","    y_hat = model(inputs)\n","    error = y_hat - y\n","    return tf.reduce_mean(tf.square(error))\n","\n","# compute the gradient of `loss_value` w.r.t `model.W` and `model.B`\n","def grad(model, inputs, targets):\n","    # here we use `tf.GradientTape` to record intermediate values of the computations\n","    # and compute gradients (as given in the example above) \n","    with tf.GradientTape() as tape:\n","        loss_value = loss(model, inputs, targets)\n","    return tape.gradient(loss_value, [model.W, model.B])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L3hUnoj_8OWG","colab_type":"text"},"source":[">**NOTE**: gradients of `loss_value` can only be taken w.r.t `tf.Variable` like `W` or `B` in class `Linear`\n","\n","**Optimizer**: helps automatically carry out variable update following some update rule (e.g. gradient descent update rule)\n","\n","**Overall code for training a simple linear model**:\n","* Create fake data for example"]},{"cell_type":"code","metadata":{"id":"tHVsaTbx9W4q","colab_type":"code","outputId":"c18b222c-56e9-414f-b3e5-7eb78871f5d0","executionInfo":{"status":"ok","timestamp":1578757382038,"user_tz":-420,"elapsed":2677,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["import matplotlib.pyplot as plt\n","\n","NUM_EXAMPLES = 2000\n","\n","# draw 2000 random numbers as the training inputs\n","training_inputs = tf.random.normal([NUM_EXAMPLES])\n","\n","# define the training targets as `y = 3*x + 2` where `x` is training inputs\n","# here we also include some noise to `y` to make the training harder\n","noise = tf.random.normal([NUM_EXAMPLES])\n","training_outputs = training_inputs * 3 + 2 + noise\n","\n","# visualize the training examples\n","plt.plot(training_inputs, training_outputs, 'o', label=\"training examples\")\n","plt.xlabel(\"X\"), plt.ylabel(\"Y\")\n","plt.title(\"Training examples\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Uov9DgmbGEfO","colab_type":"text"},"source":["* Write some code for visualization"]},{"cell_type":"code","metadata":{"id":"cYLzmOEHGEmd","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","def visualize_predictions(model, training_inputs, training_outputs):\n","    # visualize the linear model together with the training examples\n","    # to see how good the linear model is\n","    plt.plot(training_inputs, training_outputs, 'o', label=\"training examples\")\n","    plt.plot(training_inputs, model(training_inputs), label=\"regression model\")\n","    plt.xlabel(\"X\"), plt.ylabel(\"Y\")\n","    plt.title(\"Training plot\")\n","    plt.legend()\n","    plt.show()\n","\n","def visualize_learning_curve(loss_history):\n","    # plotting learning curve is plotting the loss values against the number of iterations \n","    plt.plot(range(len(loss_history)), loss_history)\n","    plt.xlabel(\"Iter\"), plt.ylabel(\"Loss\")\n","    plt.title(\"Learning curve\")\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6a1DHQP9XvH","colab_type":"text"},"source":["* Train the linear model"]},{"cell_type":"code","metadata":{"id":"ZSA1xUHj8NV7","colab_type":"code","outputId":"530639ba-e36d-41f2-ca99-b84d3517c77e","executionInfo":{"status":"error","timestamp":1578757812360,"user_tz":-420,"elapsed":1110,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":234}},"source":["# define model, optimizer and compute the initial loss\n","model = Linear()\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","\n","# print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n","\n","# train\n","loss_history = []\n","for i in range(300):\n","    grads = grad(model, training_inputs, training_outputs)\n","    optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n","    # loss_history.append(loss(model, training_inputs, training_outputs))\n","    # if i % 50 == 0:\n","    #     print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n","    #     visualize_predictions(model, training_inputs, training_outputs)\n","\n","# finalize the training by printing the final loss and plot the learning curve\n","# print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n","# visualize_learning_curve(loss_history)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-1683e8df5af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# loss_history.append(loss(model, training_inputs, training_outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"]}]},{"cell_type":"markdown","metadata":{"id":"QC8U_R3a9ku3","colab_type":"text"},"source":["* Show the values of the trained weights and biases"]},{"cell_type":"code","metadata":{"id":"5GFdJVoD9aWb","colab_type":"code","colab":{}},"source":["\n","print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ADDZjKWh9wWb","colab_type":"text"},"source":["**Saving a trained models**:\n","* Option 1: save and load weights only\n","    * Code: use `model.save_weights(\"weights\")`\n","    * Saving format: there will be files\n","        * `weights.data-00000-of-00002` and `weights.data-00001-of-00002`\n","            * Description: TensorBundle collection, which saves the values of all variables\n","        * `weights.index`: string-string immutable table containing the mapping <`tensor_name`:`tensor_value`>\n","    * Transferring weights to another computer: we have to transfer all files with prefix `weights.` (or whatever, as we declared in the saving code)\n","\n",">**NOTE**: since we save only model weights, when loading the weights back, we have to define our model first (in case our model hasn't been defined yet)"]},{"cell_type":"code","metadata":{"id":"Rrz6eQ8j94rf","colab_type":"code","colab":{}},"source":["# save weights\n","model.save_weights('weights')\n","\n","# load weights\n","status = model.load_weights('weights')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddh-ZwlhJk57","colab_type":"code","colab":{}},"source":["# checkout saved files (i.e. \"weights.data-00001-of-00002\", \"weights.data-00000-of-00002\", and \"weights.index\")\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"avMC8OyX-Hsk","colab_type":"text"},"source":["* Option 2: using checkpoint to save and load model as well as training state\n","    * Saving format: similar as option 1, but instead of files `weights.data-00000-of-00002` or `weights.index`, there will be:\n","        * `ckpt-<save_index>.data-00000-of-00002`, and `ckpt-<save_index>.data-00001-of-00002` where `<save_index>` is the number of index of the saved checkpoint \n","        \n","        >**NOTE**: not necessarily be `ckpt.`, it can be any prefix as declared in `checkpoint_prefix` below)\n","        * `ckpt-<save_index>.index`\n","\n",">**NOTE**: since we save only model weights, when loading the weights back, we have to define our model first (in case our model hasn't been defined yet)"]},{"cell_type":"code","metadata":{"id":"e-gyu8Mu95ul","colab_type":"code","colab":{}},"source":["import os\n","\n","# define and create checkpoint dir\n","checkpoint_dir = 'path/to/model_dir'\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","\n","# define checkpoint prefix\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","\n","# define `tf.train.Checkpoint` object, save, and load the training state\n","root = tf.train.Checkpoint(optimizer=optimizer,\n","                           model=model)\n","root.save(checkpoint_prefix)\n","root.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCqlgyIFIch4","colab_type":"code","colab":{}},"source":["# checkout saved files (i.e. \"ckpt-1.data-00001-of-00002\", \"ckpt-1.data-00000-of-00002\", and \"ckpt-1.index\")\n","!ls path/to/model_dir"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFVzRL_7-VWY","colab_type":"text"},"source":["**Evaluating a model**: here we use `tf.keras.metrics` to efficiently evaluate our model\n","* Example: evaluate model over the training procedure"]},{"cell_type":"code","metadata":{"id":"TjqkmPsQ-P9O","colab_type":"code","outputId":"c70e2b7e-a625-4c5c-93c0-0c75bf9b9675","executionInfo":{"status":"error","timestamp":1578757373055,"user_tz":-420,"elapsed":1152,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":234}},"source":["model = Linear()\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","\n","# declare a metric object\n","m = tf.keras.metrics.Mean(\"loss\")\n","print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n","for i in range(300):\n","    grads = grad(model, training_inputs, training_outputs)\n","    optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n","    train_loss = loss(model, training_inputs, training_outputs)\n","    if i % 20 == 0:\n","        print(\"Loss at step {:03d}: {:.3f}\".format(i, train_loss))\n","    \n","    # add `train_loss` to the metric object\n","    m(train_loss)\n","\n","# print summarized metric over the training phase\n","print(m.result())"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-d8fe6d4ad67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# declare a metric object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial loss: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'training_inputs' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"oDIhdPsGG5y_","colab_type":"text"},"source":["# Advanced TensorFlow-2.0\n","## Gradient tapes \n","**Idea**:\n","* Step 1: TensorFlow records *all operations* executed inside the context of a `tf.GradientTape` onto a \"tape\"\n","* Step 2: TensorFlow uses the tape and gradients associated with each recorded operation to compute gradients of a recorded computation\n","* Step 3: resources held by a GradientTape are released as soon as `GradientTape.gradient()` is called (by default)\n","\n","**Example code**:"]},{"cell_type":"code","metadata":{"id":"N_u0PMLkHXn4","colab_type":"code","colab":{}},"source":["x = tf.ones((2, 2))\n","\n","with tf.GradientTape() as t:\n","    t.watch(x)\n","    y = tf.reduce_sum(x)\n","    z = tf.multiply(y, y)\n","\n","# Derivative of z with respect to the original input tensor x\n","dz_dx = t.gradient(z, x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzBr3nA3HkMN","colab_type":"text"},"source":["* Explain code:\n","    * `t.watch(x)`: ensure that `x` is being traced by tape `t` so that we can compute the gradient w.r.t `x`\n","    * `t.gradient(z, x)`: compute the gradient of `z` w.r.t `x` using recoreded data in `t\n","\n","**Computing multiple gradients over the same computation**: use `persistent`"]},{"cell_type":"code","metadata":{"id":"WI7K6vIfIWRv","colab_type":"code","colab":{}},"source":["x = tf.constant(3.0)\n","with tf.GradientTape(persistent=True) as t:\n","    t.watch(x)\n","    y = x * x\n","    z = y * y\n","\n","# here we compute multiple gradients (i.e. 2 gradients)\n","dz_dx = t.gradient(z, x)\n","dy_dx = t.gradient(y, x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UEx2zJhUItTX","colab_type":"text"},"source":["**Higher-order gradients**"]},{"cell_type":"code","metadata":{"id":"AQ-WBNrOIvBC","colab_type":"code","colab":{}},"source":["x = tf.Variable(1.0)\n","\n","with tf.GradientTape() as t:\n","    with tf.GradientTape() as t2:\n","        y = x * x * x\n","    # Compute the gradient inside the 't' context manager\n","    # which means the gradient computation is differentiable as well.\n","    dy_dx = t2.gradient(y, x)\n","d2y_dx2 = t.gradient(dy_dx, x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jIar8TKXLAj7","colab_type":"text"},"source":["## Writing custom layers and models\n","### Layer\n","**Layer**: encapsulate a state (i.e. \"weights\") and a transformation from inputs to outputs (i.e. \"call\")\n","* Example code: the cell below implements a simple linear layer with trainable weights `w` and non-trainable bias `b`"]},{"cell_type":"code","metadata":{"id":"75On54qrLyKK","colab_type":"code","colab":{}},"source":["from tensorflow.keras import layers\n","\n","class Linear(layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super(Linear, self).__init__()\n","        # trainable weights\n","        w_init = tf.random_normal_initializer()\n","        self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units), dtype='float32'), \n","                             trainable=True)\n","        # non-trainable weights\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(initial_value=b_init(shape=(units,), dtype='float32'), \n","                             trainable=False)\n","\n","    def call(self, inputs):\n","      return tf.matmul(inputs, self.w) + self.b\n","\n","x = tf.ones((2, 2))\n","linear_layer = Linear(4, 2)\n","y = linear_layer(x)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6gWOAbQCMgtO","colab_type":"text"},"source":["* Adding weights to `tf.layers.Layer` by `add_weight` method: another way to define layer's weights"]},{"cell_type":"code","metadata":{"id":"f42vhDzFMmhw","colab_type":"code","colab":{}},"source":["class Linear(layers.Layer):\n","    def __init__(self , units=32, input_dim=32):\n","        super(Linear, self).__init__()\n","        self.w = self.add_weight(shape=(input_dim, units),\n","                                    initializer='random_normal',\n","                                    trainable=True)\n","        self.b = self.add_weight(shape=(units,),\n","                                    initializer='zeros',\n","                                    trainable=False)\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","x = tf.ones((2, 2))\n","linear_layer = Linear(4, 2)\n","y = linear_layer(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LYATJCmSLluH","colab_type":"text"},"source":["**Layer-in-layer**: layers can be recursively composable"]},{"cell_type":"code","metadata":{"id":"WhHANdJtLb6P","colab_type":"code","outputId":"2a996e13-a2fe-4c3a-cebe-dbf46566c230","executionInfo":{"status":"ok","timestamp":1578757893561,"user_tz":-420,"elapsed":1138,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["class MLPBlock(layers.Layer):\n","    def __init__(self):\n","        super(MLPBlock, self).__init__()\n","        self.linear_1 = Linear(32, 64)\n","        self.linear_2 = Linear(32, 32)\n","        self.linear_3 = Linear(1, 32)\n","\n","    def call(self, inputs):\n","        x = self.linear_1(inputs)\n","        x = tf.nn.relu(x)\n","        x = self.linear_2(x)\n","        x = tf.nn.relu(x)\n","        return self.linear_3(x)\n","\n","mlp = MLPBlock()\n","y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n","print('weights:', len(mlp.weights))\n","print('trainable weights:', len(mlp.trainable_weights))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["weights: 6\n","trainable weights: 3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_izCEtLGN3Oe","colab_type":"text"},"source":["**In-layer loss**: use `add_loss(value)` method\n","* Usage: used for adding layer-wise loss like $L_2$ regularization loss"]},{"cell_type":"code","metadata":{"id":"nEdRBkvBN-tA","colab_type":"code","colab":{}},"source":["class Linear(layers.Layer):\n","    def __init__(self, units=32, input_dim=32):\n","        super(Linear, self).__init__()\n","        self.w = self.add_weight(shape=(input_dim, units),\n","                                    initializer='random_normal',\n","                                    trainable=True)\n","        self.b = self.add_weight(shape=(units,),\n","                                    initializer='zeros',\n","                                    trainable=False)\n","\n","    def call(self, inputs):\n","        # calculate L2 regularization loss\n","        self.add_loss(tf.sqrt(tf.reduce_sum(self.w**2)) \\\n","                      + tf.sqrt(tf.reduce_sum(self.b**2)))\n","        # calculate the linear transformation\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","x = tf.ones((2, 2))\n","linear_layer = Linear(4, 2)\n","y = linear_layer(x)\n","\n","# retrieve the calculated L2 regularization loss\n","l2_regularization = linear_layer.losses"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YWiHW-NhOOJp","colab_type":"text"},"source":["* Overall training script with in-layer loss"]},{"cell_type":"code","metadata":{"id":"h_8Fh7nXOPCa","colab_type":"code","outputId":"5cd1aa1b-ef23-40a9-9289-b51bb56a9cac","executionInfo":{"status":"error","timestamp":1578757968967,"user_tz":-420,"elapsed":1267,"user":{"displayName":"Lê An","photoUrl":"","userId":"03692660824689564584"}},"colab":{"base_uri":"https://localhost:8080/","height":234}},"source":["# Instantiate an optimizer.\n","optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Iterate over the batches of a dataset.\n","for x_batch_train, y_batch_train in train_dataset:\n","    with tf.GradientTape() as tape:\n","        logits = layer(x_batch_train)  # Logits for this minibatch\n","        # Loss value for this minibatch\n","        loss_value = loss_fn(y_batch_train, logits)\n","        # Add extra losses created during this forward pass:\n","        loss_value += sum(model.losses)\n","\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-50232042bac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Iterate over the batches of a dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Logits for this minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Loss value for this minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'layer' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"PR9Zr05cQCYg","colab_type":"text"},"source":["### Building models\n","**The Model class**:\n","* Differences from `Layer`:\n","    * `Layer`: used to define inner computation blocks\n","    * `Model`: used to define outer model (i.e. the object we will train)\n","* Methods of `Model` which don't present in `Layer`:\n","    * `model.fit()`: train the model\n","    * `model.evaluate()`: evaluate the model\n","    * `model.predict`: use the model for prediction\n","\n","**Example code**:"]},{"cell_type":"code","metadata":{"id":"10ewbDgNQrrp","colab_type":"code","colab":{}},"source":["class ResNet(tf.keras.Model):\n","    def __init__(self):\n","        super(ResNet, self).__init__()\n","        self.block_1 = ResNetBlock()\n","        self.block_2 = ResNetBlock()\n","        self.global_pool = layers.GlobalAveragePooling2D()\n","        self.classifier = Dense(num_classes)\n","\n","    def call(self, inputs):\n","        x = self.block_1(inputs)\n","        x = self.block_2(x)\n","        x = self.global_pool(x)\n","        return self.classifier(x)\n","\n","\n","resnet = ResNet()\n","dataset = ...\n","resnet.fit(dataset, epochs=10)\n","resnet.save_weights(filepath)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4GfC81CHJLx3","colab_type":"text"},"source":["## GPU acceleration\n","**Get hosting device name of a `tf.Tensor`**: use `tf.Tensor.device`"]},{"cell_type":"code","metadata":{"id":"xEkzyJZtJYr2","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","x = tf.random.uniform([3, 3])\n","x.device"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQVmFol0JvLR","colab_type":"text"},"source":["**Device placement**: assign (place) individual operations on a device for execution"]},{"cell_type":"code","metadata":{"id":"iveAco-nJ3up","colab_type":"code","colab":{}},"source":["import time\n","\n","def time_matmul(x):\n","  start = time.time()\n","  for loop in range(1000):\n","    tf.matmul(x, x)\n","\n","  result = time.time()-start\n","\n","  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n","\n","# Force execution on CPU\n","# print(\"On CPU:\")\n","# with tf.device(\"CPU:0\"):\n","#   x = tf.random.uniform([1000, 1000])\n","#   assert x.device.endswith(\"CPU:0\")\n","#   time_matmul(x)\n","\n","# Force execution on GPU #0 if available\n","if tf.config.experimental.list_physical_devices(\"GPU\"):\n","  print(\"On GPU:\")\n","  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n","    x = tf.random.uniform([1000, 1000])\n","    assert x.device.endswith(\"GPU:0\")\n","    time_matmul(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"677DJhDm_bmC","colab_type":"text"},"source":["# CAUTION\n","If you don't know something, Google it!\n","\n","# References\n","* [TensorFlow-2.0 Python documentation](https://www.tensorflow.org/api_docs/python)\n","* [TensorFlow documentation on eager execution mode](https://www.tensorflow.org/guide/eager)"]},{"cell_type":"code","metadata":{"id":"csm0-FvjRRzg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}